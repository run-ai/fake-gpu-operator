environment:
  openshift: false

devicePlugin:
  image:
    pullPolicy: Always
    repository: gcr.io/run-ai-staging/fake-gpu-operator/device-plugin
    tag: 0.0.1
  resources: 
    requests:
      cpu: "100m"
      memory: "100Mi"
    limits:
      cpu: "200m"
      memory: "200Mi"

statusUpdater:
  image:
    pullPolicy: Always
    repository: gcr.io/run-ai-staging/fake-gpu-operator/status-updater
    tag: 0.0.1
  resources: 
    requests:
      cpu: "200m"
      memory: "200Mi"
    limits:
      cpu: "400m"
      memory: "400Mi"

topologyServer:
  image:
    pullPolicy: Always
    repository: gcr.io/run-ai-staging/fake-gpu-operator/topology-server
    tag: 0.0.1
  resources: 
    requests:
      cpu: "100m"
      memory: "100Mi"
    limits:
      cpu: "200m"
      memory: "200Mi"

statusExporter:
  image:
    pullPolicy: Always
    repository: gcr.io/run-ai-staging/fake-gpu-operator/status-exporter
    tag: 0.0.1
  resources: 
    requests:
      cpu: "100m"
      memory: "100Mi"
    limits:
      cpu: "200m"
      memory: "200Mi"
  topologyMaxExportInterval: 10s

migFaker:
  image:
    pullPolicy: Always
    repository: gcr.io/run-ai-staging/fake-gpu-operator/mig-faker
    tag: 0.0.1

initialTopology:
  config:
    node-autofill:
      gpu-count: 2
      gpu-product: Tesla-K80
      gpu-memory: 11441
  mig-strategy: mixed
  nodes: {}