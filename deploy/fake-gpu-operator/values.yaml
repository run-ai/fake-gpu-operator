environment:
  openshift: false

devicePlugin:
  image:
    pullPolicy: Always
    repository: gcr.io/run-ai-staging/fake-gpu-operator/device-plugin
    tag: 0.0.1
  resources: 
    requests:
      cpu: "100m"
      memory: "100Mi"
    limits:
      cpu: "200m"
      memory: "200Mi"

statusUpdater:
  image:
    pullPolicy: Always
    repository: gcr.io/run-ai-staging/fake-gpu-operator/status-updater
    tag: 0.0.1
  resources: 
    requests:
      cpu: "200m"
      memory: "200Mi"
    limits:
      cpu: "400m"
      memory: "400Mi"

topologyServer:
  image:
    pullPolicy: Always
    repository: gcr.io/run-ai-staging/fake-gpu-operator/topology-server
    tag: 0.0.1
  resources: 
    requests:
      cpu: "100m"
      memory: "100Mi"
    limits:
      cpu: "200m"
      memory: "200Mi"

statusExporter:
  image:
    pullPolicy: Always
    repository: gcr.io/run-ai-staging/fake-gpu-operator/status-exporter
    tag: 0.0.1
  resources: 
    requests:
      cpu: "100m"
      memory: "100Mi"
    limits:
      cpu: "200m"
      memory: "200Mi"
  topologyMaxExportInterval: 10s

migFaker:
  image:
    pullPolicy: Always
    repository: gcr.io/run-ai-staging/fake-gpu-operator/mig-faker
    tag: 0.0.1

topology:
  # nodePools is a map of node pool name to node pool configuration.
  # Nodes are assigned to node pools based on the node pool label's value (key is configurable via nodePoolLabelKey).
  # 
  # For example, nodes that have the label "run.ai/simulated-gpu-node-pool: default"
  # will be assigned to the "default" node pool.
  nodePools:
    default:
      gpuProduct: Tesla-K80
      gpuCount: 2
      gpuMemory: 11441
  nodePoolLabelKey: run.ai/simulated-gpu-node-pool
  migStrategy: mixed