environment:
  openshift: false

devicePlugin:
  image:
    pullPolicy: Always
    repository: gcr.io/run-ai-staging/fake-gpu-operator/device-plugin
    tag: 0.0.1
  resources: 
    requests:
      cpu: "100m"
      memory: "100Mi"
    limits:
      cpu: "200m"
      memory: "200Mi"

statusUpdater:
  image:
    pullPolicy: Always
    repository: gcr.io/run-ai-staging/fake-gpu-operator/status-updater
    tag: 0.0.1
  resources: 
    requests:
      cpu: "200m"
      memory: "200Mi"
    limits:
      cpu: "400m"
      memory: "400Mi"

topologyServer:
  image:
    pullPolicy: Always
    repository: gcr.io/run-ai-staging/fake-gpu-operator/topology-server
    tag: 0.0.1
  resources: 
    requests:
      cpu: "100m"
      memory: "100Mi"
    limits:
      cpu: "200m"
      memory: "200Mi"

statusExporter:
  image:
    pullPolicy: Always
    repository: gcr.io/run-ai-staging/fake-gpu-operator/status-exporter
    tag: 0.0.1
  resources: 
    requests:
      cpu: "100m"
      memory: "100Mi"
    limits:
      cpu: "200m"
      memory: "200Mi"
  topologyMaxExportInterval: 10s

initialTopology:
  config:
    node-autofill:
      enabled: true
      gpu-count: 2
      gpu-product: Tesla-K80
      gpu-memory: 11441
  mig-strategy: mixed
  nodes: {}
    # nodes can be defined in the following way:
    # runai-worker:
    #   gpu-count: 8
    #   gpu-memory: 11441
    #   gpu-product: Tesla-K80
    # runai-worker2:
    #   gpu-count: 16
    #   gpu-memory: 11441
    #   gpu-product: Tesla-K80